{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.http import HtmlResponse\n",
    "from scrapy import Selector\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "from importlib import reload\n",
    "import sys\n",
    "sys.path.append('/home/nur/projects/analysis/range_matching')\n",
    "import imdb_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW [Link](https://www.imdb.com/search/name/?gender=male%2Cfemale&ref_=nv_cel_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG_URL = 'https://www.imdb.com/title/tt11041332/fullcredits?ref_=tt_cl_sm#cast'\n",
    "\n",
    "req = requests.get(DEBUG_URL)\n",
    "response = HtmlResponse(url=DEBUG_URL, body=req.content)\n",
    "\n",
    "selector = Selector(response=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = selector.xpath(\".//div[@class='subpage_title_block__right-column']\"\n",
    "                    \"/div[@class='parent']/h3/a/text()\").extract_first().strip()\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger('scrapy').disabled=True\n",
    "logging.getLogger().setLevel(logging.WARNING);\n",
    "\n",
    "class ActorItem(scrapy.Item):\n",
    "    name = scrapy.Field()\n",
    "    born = scrapy.Field()\n",
    "    movies = scrapy.Field()\n",
    "    url = scrapy.Field()\n",
    "    bio = scrapy.Field()\n",
    "\n",
    "class MovieItem(scrapy.Item):\n",
    "    url = scrapy.Field()\n",
    "    title = scrapy.Field()\n",
    "    cast = scrapy.Field()\n",
    "\n",
    "IS_ACTOR = False\n",
    "    \n",
    "class ImdbSpider(scrapy.Spider):\n",
    "    name = 'imdb'\n",
    "    allowed_domains = [\"imdb.com\"]\n",
    "    base_url = \"https://www.imdb.com\"\n",
    "    start_urls = [\"https://www.imdb.com/search/name/?gender=male%2Cfemale&ref_=nv_cel_m\"]\n",
    "    \n",
    "    def parse(self, response):\n",
    "        url_parts = response.xpath(\".//*[@class='lister-item-content']/h3[@class='lister-item-header']\"\n",
    "                                   \"/a/@href\").extract()\n",
    "        actor_url_list = [self.base_url + x for x in url_parts]\n",
    "        if IS_ACTOR:\n",
    "            for actor_url in actor_url_list:\n",
    "                yield scrapy.Request(actor_url,\n",
    "                                     callback=self.parse_actor,\n",
    "                                     meta={'url':actor_url + \"/\"})\n",
    "        else:\n",
    "            if os.path.exists('gen_movie.pkl'):\n",
    "                movie_url_list = list(self.gen_movie(actor_url_list))\n",
    "                with open('gen_movie.pkl', 'wb') as f:\n",
    "                    pickle.dump(movie_url_list, 'gen_movie.pkl')\n",
    "            else:\n",
    "                with opne('gen_movie.pkl', 'rb') as f:\n",
    "                    movie_url_list = pickle.load(f)\n",
    "            \n",
    "            for movie_url in movie_url_list:\n",
    "                yield scrapy.Request(movie_url + 'fullcredits',\n",
    "                                     callback=self.parse_cast,\n",
    "                                     meta={'url': movie_url})\n",
    "    \n",
    "    def gen_movie(self, actor_url_list):\n",
    "        already_parsed = set()\n",
    "        for actor_url in actor_url_list:\n",
    "            response = HtmlResponse(url=actor_url, body=requests.get(actor_url).content)\n",
    "            selector = Selector(response=response)\n",
    "            \n",
    "            movie_url_list = selector.xpath(\".//div[@class='filmo-category-section']\"\n",
    "                                        \"/div/b/a/@href\").extract()\n",
    "            movie_url_list = set(movie_url_list) - already_parsed\n",
    "            for movie_url in movie_url_list:\n",
    "                movie_url = self.base_url + movie_url\n",
    "                yield movie_url\n",
    "            already_parsed |= movie_url_list\n",
    "       \n",
    "    def parse_cast(self, response):\n",
    "        item = MovieItem()\n",
    "        \n",
    "        item['url'] = response.meta['url']\n",
    "        item['title'] = response.xpath(\".//div[@class='subpage_title_block__right-column']\"\n",
    "                    \"/div[@class='parent']/h3/a/text()\").extract_first().strip()\n",
    "        res = response.xpath(\".//table[@class='cast_list']//tr/td[2]/a/text()\").extract()\n",
    "        item['cast'] = list(map(str.strip, res))\n",
    "        return item\n",
    "        \n",
    "    def parse_actor(self, response):\n",
    "        item = ActorItem()\n",
    "        \n",
    "        item['name'] = response.xpath(\".//td[@class='name-overview-widget__section']\"\n",
    "                                     \"/h1/span/text()\").extract_first().strip()\n",
    "        \n",
    "        bio_part = response.xpath(\".//div[@class='name-trivia-bio-text']/div/\"\n",
    "                    \"/descendant-or-self::text()\").extract()\n",
    "        stop_word =\"See full bio\"\n",
    "        bio_str_list = []\n",
    "        for r in bio_part:\n",
    "            if r == stop_word:\n",
    "                break\n",
    "            bio_str_list.append(r)\n",
    "        item['bio'] = \" \".join(bio_str_list).strip()\n",
    "        \n",
    "        item['born'] = response.xpath(\".//time/@datetime\").extract_first()\n",
    "        \n",
    "        item['url'] = response.meta['url']\n",
    "        \n",
    "        movie_list = response.xpath(\".//div[@class='filmo-category-section']/div/b/a/text()\").extract()\n",
    "        item['movies'] = list(map(str.strip, movie_list[:15]))\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r = ImdbSpider()\n",
    "for s in r.gen_movie(['/name/nm3480246/']):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf items.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-01 23:24:27 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: scrapybot)\n",
      "2021-06-01 23:24:27 [scrapy.utils.log] INFO: Versions: lxml 4.6.3.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.10 (default, May  3 2021, 02:48:31) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1k  25 Mar 2021), cryptography 3.4.7, Platform Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-Ubuntu-18.04-bionic\n",
      "2021-06-01 23:24:27 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
      "2021-06-01 23:24:27 [scrapy.crawler] INFO: Overridden settings:\n",
      "{}\n",
      "2021-06-01 23:24:27 [scrapy.extensions.telnet] INFO: Telnet Password: 00c2fcfbf8ad7ef9\n",
      "2021-06-01 23:24:27 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2021-06-01 23:24:27 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2021-06-01 23:24:27 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2021-06-01 23:24:27 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2021-06-01 23:24:27 [scrapy.core.engine] INFO: Spider opened\n",
      "2021-06-01 23:24:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2021-06-01 23:24:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2021-06-01 23:24:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.imdb.com/search/name/?gender=male%2Cfemale&ref_=nv_cel_m> (referer: None)\n",
      "2021-06-01 23:24:30 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): www.imdb.com:443\n",
      "2021-06-01 23:24:31 [urllib3.connectionpool] DEBUG: https://www.imdb.com:443 \"GET /name/nm3480246 HTTP/1.1\" 301 0\n",
      "2021-06-01 23:24:32 [urllib3.connectionpool] DEBUG: https://www.imdb.com:443 \"GET /name/nm3480246/ HTTP/1.1\" 200 None\n",
      "2021-06-01 23:24:33 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): www.imdb.com:443\n",
      "2021-06-01 23:24:33 [urllib3.connectionpool] DEBUG: https://www.imdb.com:443 \"GET /name/nm2482391 HTTP/1.1\" 301 0\n",
      "2021-06-01 23:24:33 [urllib3.connectionpool] DEBUG: https://www.imdb.com:443 \"GET /name/nm2482391/ HTTP/1.1\" 200 None\n",
      "2021-06-01 23:24:34 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): www.imdb.com:443\n",
      "2021-06-01 23:24:34 [urllib3.connectionpool] DEBUG: https://www.imdb.com:443 \"GET /name/nm0478886 HTTP/1.1\" 301 0\n",
      "2021-06-01 23:24:34 [urllib3.connectionpool] DEBUG: https://www.imdb.com:443 \"GET /name/nm0478886/ HTTP/1.1\" 200 None\n",
      "2021-06-01 23:24:35 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force \n",
      "2021-06-01 23:24:35 [scrapy.core.engine] INFO: Closing spider (shutdown)\n",
      "2021-06-01 23:24:35 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): www.imdb.com:443\n",
      "2021-06-01 23:24:35 [urllib3.connectionpool] DEBUG: https://www.imdb.com:443 \"GET /name/nm5896355 HTTP/1.1\" 301 0\n",
      "2021-06-01 23:24:35 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown\n",
      "2021-06-01 23:24:35 [urllib3.connectionpool] DEBUG: https://www.imdb.com:443 \"GET /name/nm5896355/ HTTP/1.1\" 200 None\n",
      "2021-06-01 23:24:36 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): www.imdb.com:443\n",
      "2021-06-01 23:24:36 [urllib3.connectionpool] DEBUG: https://www.imdb.com:443 \"GET /name/nm0680983 HTTP/1.1\" 301 0\n",
      "2021-06-01 23:24:37 [urllib3.connectionpool] DEBUG: https://www.imdb.com:443 \"GET /name/nm0680983/ HTTP/1.1\" 200 None\n",
      "2021-06-01 23:24:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.imdb.com//title/tt1935859/fullcredits> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]\n",
      "2021-06-01 23:24:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.imdb.com//title/tt3292080/fullcredits> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]\n",
      "2021-06-01 23:24:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.imdb.com//title/tt0872057/fullcredits> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]\n",
      "2021-06-01 23:24:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.imdb.com//title/tt2674454/fullcredits> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]\n",
      "2021-06-01 23:24:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.imdb.com//title/tt6290798/fullcredits> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]\n",
      "2021-06-01 23:24:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.imdb.com//title/tt4615318/fullcredits> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]\n",
      "2021-06-01 23:24:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.imdb.com//title/tt9642982/fullcredits> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]\n"
     ]
    }
   ],
   "source": [
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "process = CrawlerProcess(\n",
    "    settings={\n",
    "        \"FEEDS\": {\n",
    "            \"actors.json\" if IS_ACTOR else \"movies.json\": {\"format\": \"json\"}\n",
    "        }\n",
    "    }\n",
    ")\n",
    "process.crawl(ImdbSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('movies.json', 'r') as f:\n",
    "    res = json.load(f, )\n",
    "res[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0]['bio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй файл\n",
    "1. Ссылка на страницу фильма (ключ url). https://www.imdb.com/ в начале и закрывающий / в конце обязательны для прохождения проверки.\n",
    "1. Название фильма (ключ title). \n",
    "1. Список актёров (ключ cast) - List[str] с перечислением имён (чтобы они вязались с п.4 предыдущего списка)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ImdbSpider(scrapy.Spider):\n",
    "    name = \"imdb\"\n",
    "    allowed_domains = [\"imdb.com\"]\n",
    "    start_urls = ['http://www.imdb.com/chart/top',]\n",
    "   \n",
    "    def parse(self, response):\n",
    "        # получение таблицы со строками, хараактеризующими ТОП-фильмы\n",
    "        table_rows = response.xpath(\n",
    "            './/*[@class=\"chart full-width\" and @data-caller-name=\"chart-top250movie\"]/'\n",
    "            'tbody[@class=\"lister-list\"]/tr'\n",
    "        \n",
    "        )\n",
    "        \n",
    "        for row in table_rows:\n",
    "            # для каждой строки извлечем необходимую информацию\n",
    "            yield {\n",
    "                # пока парсим 3 колонки\n",
    "                \"title\": row.xpath(\"./td[@class='titleColumn']/a/text()\").extract_first(),\n",
    "                \"year\": row.xpath(\"./td[@class='titleColumn']/span/text()\").extract_first().strip(\"() \"),\n",
    "                \"rating\": row.xpath(\"./td[@class='ratingColumn imdbRating']/strong/text()\").extract_first(),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DEBUG_URL = 'http://www.imdb.com/chart/top'\n",
    "\n",
    "req = requests.get(DEBUG_URL)\n",
    "response = HtmlResponse(url=DEBUG_URL, body=req.content)\n",
    "\n",
    "selector = Selector(response=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selector.xpath('.//*[@class=\"chart full-width\" and @data-caller-name=\"chart-top250movie\"]'\n",
    "               '/tbody[@class=\"lister-list\"]')[0].extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selector.xpath('.//*[@class=\"chart full-width\" and @data-caller-name=\"chart-top250movie\"]'\n",
    "               '/tbody[@class=\"lister-list\"]/tr')[0].extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "process = CrawlerProcess()\n",
    "\n",
    "process.crawl(ImdbSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
