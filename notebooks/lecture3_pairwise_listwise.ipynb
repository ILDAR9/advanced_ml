{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RankNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%latex\n",
    "$$C_{ij}=C(o_{ij})=-\\bar{P_{ij}}log(P_{ij})-(1-\\bar{P_{ij}})log(1-P_{ij})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%latex\n",
    "$$o_{ij}=f(x_i)-f(x_j)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%latex\n",
    "$$P_{ij}=\\frac{e^{o_{ij}}}{1+e^{o_{ij}}}$$\n",
    "# torch.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%latex\n",
    "$$\\text{out}_{i} = \\frac{1}{1 + e^{-\\text{input}_{i}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class RankNet(torch.nn.Module):\n",
    "    def __init__(self, num_input_features, hidden_dim=10):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_input_features, self.hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(self.hidden_dim, 1),\n",
    "        )\n",
    "        \n",
    "        self.out_activation = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_1, input_2):\n",
    "        logits_1 = self.predict(input_1)\n",
    "        logits_2 = self.predict(input_2)\n",
    "        \n",
    "        logits_diff = logits_1 - logits_2\n",
    "        out = self.out_activation(logits_diff)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def predict(self, inp):\n",
    "        logits = self.model(inp)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranknet_model = RankNet(num_input_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_1, inp_2 = torch.rand(4, 10), torch.rand(4, 10)\n",
    "# batch_size x input_dim\n",
    "inp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ranknet_model(inp_1, inp_2)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_linear_layer = ranknet_model.model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_linear_layer.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()\n",
    "targets = torch.ones_like(preds)\n",
    "loss = criterion(preds, targets)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_linear_layer.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranknet_model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ListNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import sys\n",
    "from importlib import reload\n",
    "sys.path.append('../range_matching')\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListNet(torch.nn.Module):\n",
    "    def __init__(self, num_input_features, hidden_dim=10):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_input_features, self.hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(self.hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input_1):\n",
    "        logits = self.model(input_1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$CE = -\\sum ^{N}_{j=1} (P_y^i(j) * log(P_z^i(j)))$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$CE = -\\sum ^{N}_{j=1} (P_y^i(j) * log(P_z^i(j)))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listnet_ce_loss(y_i, z_i):\n",
    "    \"\"\"\n",
    "    y_i: (n_i, 1) GT\n",
    "    z_i: (n_i, 1) preds\n",
    "    \"\"\"\n",
    "\n",
    "    P_y_i = torch.softmax(y_i, dim=0)\n",
    "    P_z_i = torch.softmax(z_i, dim=0)\n",
    "    return -torch.sum(P_y_i * torch.log(P_z_i))\n",
    "\n",
    "def listnet_kl_loss(y_i, z_i):\n",
    "    \"\"\"\n",
    "    y_i: (n_i, 1) GT\n",
    "    z_i: (n_i, 1) preds\n",
    "    \"\"\"\n",
    "    P_y_i = torch.softmax(y_i, dim=0)\n",
    "    P_z_i = torch.softmax(z_i, dim=0)\n",
    "    return -torch.sum(P_y_i * torch.log(P_z_i/P_y_i))\n",
    "\n",
    "\n",
    "def make_dataset(N_train, N_valid, vector_dim):\n",
    "    fake_weights = torch.randn(vector_dim, 1)\n",
    "\n",
    "    X_train = torch.randn(N_train, vector_dim)\n",
    "    X_valid = torch.randn(N_valid, vector_dim)\n",
    "\n",
    "    ys_train_score = torch.mm(X_train, fake_weights)\n",
    "    ys_train_score += torch.randn_like(ys_train_score)\n",
    "\n",
    "    ys_valid_score = torch.mm(X_valid, fake_weights)\n",
    "    ys_valid_score += torch.randn_like(ys_valid_score)\n",
    "\n",
    "#     bins = [-1, 1]  # 3 relevances\n",
    "    bins = [-1, 0, 1, 2]  # 5 relevances\n",
    "    ys_train_rel = torch.Tensor(\n",
    "        np.digitize(ys_train_score.clone().detach().numpy(), bins=bins)\n",
    "    )\n",
    "    ys_valid_rel = torch.Tensor(\n",
    "        np.digitize(ys_valid_score.clone().detach().numpy(), bins=bins)\n",
    "    )\n",
    "\n",
    "    return X_train, X_valid, ys_train_rel, ys_valid_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 1000\n",
    "N_valid = 500\n",
    "\n",
    "vector_dim = 100\n",
    "epochs = 2\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "X_train, X_valid, ys_train, ys_valid = make_dataset(N_train, N_valid, vector_dim)\n",
    "\n",
    "net = ListNet(num_input_features=vector_dim)\n",
    "opt = torch.optim.Adam(net.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(metrics)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    idx = torch.randperm(N_train)\n",
    "\n",
    "    X_train = X_train[idx]\n",
    "    ys_train = ys_train[idx]\n",
    "\n",
    "    cur_batch = 0\n",
    "    for it in range(N_train // batch_size):\n",
    "        batch_X = X_train[cur_batch: cur_batch + batch_size]\n",
    "        batch_ys = ys_train[cur_batch: cur_batch + batch_size]\n",
    "        cur_batch += batch_size\n",
    "\n",
    "        opt.zero_grad()\n",
    "        if len(batch_X) > 0:\n",
    "            batch_pred = net(batch_X)\n",
    "#             batch_loss = listnet_kl_loss(batch_ys, batch_pred)\n",
    "            batch_loss = listnet_ce_loss(batch_ys, batch_pred)\n",
    "            batch_loss.backward(retain_graph=True)\n",
    "            opt.step()\n",
    "\n",
    "        if it % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                valid_pred = net(X_valid).squeeze()\n",
    "                ys_valid = ys_valid.squeeze()\n",
    "                valid_swapped_pairs = metrics.num_swapped_pairs(ys_valid, valid_pred)\n",
    "                ndcg_score = metrics.ndcg(ys_valid, valid_pred)\n",
    "            print(f\"epoch: {epoch + 1}.\\tNumber of swapped pairs: \" \n",
    "                  f\"{valid_swapped_pairs}/{N_valid * (N_valid - 1) // 2}\\t\"\n",
    "                  f\"nDCG: {ndcg_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from catboost.datasets import msrank_10k\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = msrank_10k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solution():\n",
    "    def __init__(self):\n",
    "        self._prepare_data()\n",
    "    \n",
    "    def _get_data(self) -> List[np.ndarray]:\n",
    "        train_df, test_df = msrank_10k()\n",
    "\n",
    "        X_train = train_df.drop([0, 1], axis=1).values\n",
    "        y_train = train_df[0].values\n",
    "        query_ids_train = train_df[1].values.astype(int)\n",
    "\n",
    "        X_test = test_df.drop([0, 1], axis=1).values\n",
    "        y_test = test_df[0].values\n",
    "        query_ids_test = test_df[1].values.astype(int)\n",
    "\n",
    "        return [X_train, y_train, query_ids_train, X_test, y_test, query_ids_test]\n",
    "\n",
    "    def _prepare_data(self) -> None:\n",
    "        (X_train, y_train, self.query_ids_train,\n",
    "            X_test, y_test, self.query_ids_test) = self._get_data()\n",
    "        \"\"\"\n",
    "        Отнормировать признаки X_train и X_test в рамках каждого отдельного идентификатора запроса\n",
    "        \"\"\"\n",
    "        # _scale_features_in_query_groups(...)\n",
    "        # поместить все переменные с признаками и таргетами в тензоры (torch.FloatTensor) NxD (D-features)\n",
    "        X_train = self._scale_features_in_query_groups(X_train, self.query_ids_train)\n",
    "        X_test = self._scale_features_in_query_groups(X_test, self.query_ids_test)\n",
    "        self.X_train = torch.FloatTensor(X_train)\n",
    "        self.X_test = torch.FloatTensor(X_test)\n",
    "        self.y_train = torch.FloatTensor(y_train)\n",
    "        self.y_test = torch.FloatTensor(y_test)\n",
    "\n",
    "    def _scale_features_in_query_groups(self, inp_feat_array: np.ndarray, inp_query_ids: np.ndarray) -> np.ndarray:\n",
    "        x = inp_feat_array.copy()\n",
    "        for qid in np.unique(inp_query_ids):\n",
    "            idx = inp_query_ids == qid\n",
    "            x[idx] = StandardScaler().fit_transform(inp_feat_array[idx])\n",
    "        return x\n",
    "\n",
    "s = Solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0, 1.0, 2.0, 3.0, 4.0}"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(s.y_train.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 3., ..., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(s.y_test, axis=-1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
